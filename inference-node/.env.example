INF_HOST=0.0.0.0
INF_PORT=9000
LLAMA_SERVER_URL=http://127.0.0.1:8080
LLAMA_CPP_SERVER_BIN=/opt/llama.cpp/build/bin/llama-server
LLAMA_MODEL_PATH=/models/qwen2.5-14b-instruct-q4_k_m.gguf
LLAMA_CTX_SIZE=12288
LLAMA_N_GPU_LAYERS=33
LLAMA_THREADS=12
LLAMA_BATCH=512
AUTO_LAUNCH_LLAMA=false
